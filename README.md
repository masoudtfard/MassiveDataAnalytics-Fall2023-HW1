# Massive Data Analytics Course - HW1 - Fall 2023
## Sharif University of Technology
### Introduction to PySpark


This homework involves a series of tasks focused on processing and analyzing a dataset of Persian news articles. The tasks are outlined as follows:

### Initial Setup

1. Download the dataset related to Persian news from the provided link and place it in the appropriate directory.
2. Run the cells in the `question1.ipynb` Jupyter notebook to load the dataset into an RDD format.

### Data Cleaning and Normalization

- Clean and normalize the body text of the news articles by removing non-alphanumeric characters, punctuation marks, and stopwords.

### Visualization

- Answer the questions by providing appropriate visualizations of the results.
- Use a word cloud to display the top 20 keywords, focusing on the word with the highest frequency.

### Algorithm Implementation

- Develop an algorithm to identify sets of three words that frequently appear together.
- Validate the results using the TF-IDF algorithm and suggest methods for further validation.

